================================================
Source folder images: RGB/oversampling/
Freezing until layer: 30
Number of epochs: 200
Batch size: 32
Training on GPU: True
================================================
Train: 5664 samples
	Stress: 2812 (49.65%)
	Neutral: 2852 (50.35%)
Validation: 1416 samples
	Stress: 706 (49.86%)
	Neutral: 710 (50.14%)
Test: 1770 samples
	Stress: 882 (49.83%)
	Neutral: 888 (50.17%)
================================================
N epochs: 200

Epoch 1 - 2019-08-05T17:41:19.905258
	Training Loss: 0.116586 	Validation Loss: 2.345680
	Validation loss decreased (inf --> 2.345680).  Saving model ...
	Saving the model in path: data/models/2019-08-05T17:41:19.905244.pth

Epoch 2 - 2019-08-05T17:42:46.595982
	Training Loss: 0.188651 	Validation Loss: 2.258374
	Validation loss decreased (2.345680 --> 2.258374).  Saving model ...
	Saving the model in path: data/models/2019-08-05T17:41:19.905244.pth

Epoch 3 - 2019-08-05T17:44:13.340082
	Training Loss: 0.194079 	Validation Loss: 2.196564
	Validation loss decreased (2.258374 --> 2.196564).  Saving model ...
	Saving the model in path: data/models/2019-08-05T17:41:19.905244.pth

Epoch 4 - 2019-08-05T17:45:40.186374
	Training Loss: 0.199501 	Validation Loss: 2.117362
	Validation loss decreased (2.196564 --> 2.117362).  Saving model ...
	Saving the model in path: data/models/2019-08-05T17:41:19.905244.pth

Epoch 5 - 2019-08-05T17:47:07.138361
	Training Loss: 0.205461 	Validation Loss: 2.065491
	Validation loss decreased (2.117362 --> 2.065491).  Saving model ...
	Saving the model in path: data/models/2019-08-05T17:41:19.905244.pth

Epoch 6 - 2019-08-05T17:48:34.689627
	Training Loss: 0.212252 	Validation Loss: 2.001826
	Validation loss decreased (2.065491 --> 2.001826).  Saving model ...
	Saving the model in path: data/models/2019-08-05T17:41:19.905244.pth

Epoch 7 - 2019-08-05T17:50:01.637154
	Training Loss: 0.219214 	Validation Loss: 1.946296
	Validation loss decreased (2.001826 --> 1.946296).  Saving model ...
	Saving the model in path: data/models/2019-08-05T17:41:19.905244.pth

Epoch 8 - 2019-08-05T17:51:29.566577
	Training Loss: 0.222406 	Validation Loss: 1.903113
	Validation loss decreased (1.946296 --> 1.903113).  Saving model ...
	Saving the model in path: data/models/2019-08-05T17:41:19.905244.pth

Epoch 9 - 2019-08-05T17:52:58.464621
	Training Loss: 0.227962 	Validation Loss: 1.865116
	Validation loss decreased (1.903113 --> 1.865116).  Saving model ...
	Saving the model in path: data/models/2019-08-05T17:41:19.905244.pth

Epoch 10 - 2019-08-05T17:54:25.544429
	Training Loss: 0.232586 	Validation Loss: 1.816778
	Validation loss decreased (1.865116 --> 1.816778).  Saving model ...
	Saving the model in path: data/models/2019-08-05T17:41:19.905244.pth

Epoch 11 - 2019-08-05T17:55:54.054571
	Training Loss: 0.237159 	Validation Loss: 1.786123
	Validation loss decreased (1.816778 --> 1.786123).  Saving model ...
	Saving the model in path: data/models/2019-08-05T17:41:19.905244.pth

Epoch 12 - 2019-08-05T17:57:26.093206
	Training Loss: 0.241352 	Validation Loss: 1.746341
	Validation loss decreased (1.786123 --> 1.746341).  Saving model ...
	Saving the model in path: data/models/2019-08-05T17:41:19.905244.pth

Epoch 13 - 2019-08-05T17:59:02.114601
	Training Loss: 0.242738 	Validation Loss: 1.722186
	Validation loss decreased (1.746341 --> 1.722186).  Saving model ...
	Saving the model in path: data/models/2019-08-05T17:41:19.905244.pth

Epoch 14 - 2019-08-05T18:00:36.854170
	Training Loss: 0.245877 	Validation Loss: 1.699739
	Validation loss decreased (1.722186 --> 1.699739).  Saving model ...
	Saving the model in path: data/models/2019-08-05T17:41:19.905244.pth

Epoch 15 - 2019-08-05T18:02:05.836220
	Training Loss: 0.248558 	Validation Loss: 1.670096
	Validation loss decreased (1.699739 --> 1.670096).  Saving model ...
	Saving the model in path: data/models/2019-08-05T17:41:19.905244.pth

Epoch 16 - 2019-08-05T18:03:32.792139
	Training Loss: 0.249333 	Validation Loss: 1.653086
	Validation loss decreased (1.670096 --> 1.653086).  Saving model ...
	Saving the model in path: data/models/2019-08-05T17:41:19.905244.pth

Epoch 17 - 2019-08-05T18:04:59.739497
	Training Loss: 0.250962 	Validation Loss: 1.622807
	Validation loss decreased (1.653086 --> 1.622807).  Saving model ...
	Saving the model in path: data/models/2019-08-05T17:41:19.905244.pth

Epoch 18 - 2019-08-05T18:06:28.566603
	Training Loss: 0.253205 	Validation Loss: 1.604804
	Validation loss decreased (1.622807 --> 1.604804).  Saving model ...
	Saving the model in path: data/models/2019-08-05T17:41:19.905244.pth

Epoch 19 - 2019-08-05T18:07:57.235907
	Training Loss: 0.250817 	Validation Loss: 1.598857
	Validation loss decreased (1.604804 --> 1.598857).  Saving model ...
	Saving the model in path: data/models/2019-08-05T17:41:19.905244.pth

Epoch 20 - 2019-08-05T18:09:28.217306
	Training Loss: 0.253505 	Validation Loss: 1.595307
	Validation loss decreased (1.598857 --> 1.595307).  Saving model ...
	Saving the model in path: data/models/2019-08-05T17:41:19.905244.pth

Epoch 21 - 2019-08-05T18:10:57.449464
	Training Loss: 0.256411 	Validation Loss: 1.564700
	Validation loss decreased (1.595307 --> 1.564700).  Saving model ...
	Saving the model in path: data/models/2019-08-05T17:41:19.905244.pth

Epoch 22 - 2019-08-05T18:12:27.600155
	Training Loss: 0.256086 	Validation Loss: 1.559178
	Validation loss decreased (1.564700 --> 1.559178).  Saving model ...
	Saving the model in path: data/models/2019-08-05T17:41:19.905244.pth

Epoch 23 - 2019-08-05T18:13:56.986923
	Training Loss: 0.257828 	Validation Loss: 1.542422
	Validation loss decreased (1.559178 --> 1.542422).  Saving model ...
	Saving the model in path: data/models/2019-08-05T17:41:19.905244.pth

Epoch 24 - 2019-08-05T18:15:27.827775
	Training Loss: 0.255774 	Validation Loss: 1.525081
	Validation loss decreased (1.542422 --> 1.525081).  Saving model ...
	Saving the model in path: data/models/2019-08-05T17:41:19.905244.pth

Epoch 25 - 2019-08-05T18:16:58.969007
	Training Loss: 0.252992 	Validation Loss: 1.518492
	Validation loss decreased (1.525081 --> 1.518492).  Saving model ...
	Saving the model in path: data/models/2019-08-05T17:41:19.905244.pth

Epoch 26 - 2019-08-05T18:18:28.072610
	Training Loss: 0.257309 	Validation Loss: 1.510807
	Validation loss decreased (1.518492 --> 1.510807).  Saving model ...
	Saving the model in path: data/models/2019-08-05T17:41:19.905244.pth

Epoch 27 - 2019-08-05T18:20:00.931726
	Training Loss: 0.256838 	Validation Loss: 1.498661
	Validation loss decreased (1.510807 --> 1.498661).  Saving model ...
	Saving the model in path: data/models/2019-08-05T17:41:19.905244.pth

Epoch 28 - 2019-08-05T18:21:31.638080
	Training Loss: 0.252429 	Validation Loss: 1.489590
	Validation loss decreased (1.498661 --> 1.489590).  Saving model ...
	Saving the model in path: data/models/2019-08-05T17:41:19.905244.pth

Epoch 29 - 2019-08-05T18:23:02.719162
	Training Loss: 0.252980 	Validation Loss: 1.497552

Epoch 30 - 2019-08-05T18:24:32.854118
	Training Loss: 0.250264 	Validation Loss: 1.470257
	Validation loss decreased (1.489590 --> 1.470257).  Saving model ...
	Saving the model in path: data/models/2019-08-05T17:41:19.905244.pth

Epoch 31 - 2019-08-05T18:26:09.089473
	Training Loss: 0.248884 	Validation Loss: 1.495699

Epoch 32 - 2019-08-05T18:27:42.831487
	Training Loss: 0.246804 	Validation Loss: 1.478351

Epoch 33 - 2019-08-05T18:29:11.598086
	Training Loss: 0.243707 	Validation Loss: 1.491463

Epoch 34 - 2019-08-05T18:30:40.590387
	Training Loss: 0.241247 	Validation Loss: 1.489051

Epoch 35 - 2019-08-05T18:32:10.846049
	Training Loss: 0.236732 	Validation Loss: 1.507336

Epoch 36 - 2019-08-05T18:33:40.907164
	Training Loss: 0.239063 	Validation Loss: 1.486650

Epoch 37 - 2019-08-05T18:35:09.910160
	Training Loss: 0.232381 	Validation Loss: 1.498207

Epoch 38 - 2019-08-05T18:36:37.715383
	Training Loss: 0.230560 	Validation Loss: 1.505695

Epoch 39 - 2019-08-05T18:38:05.924228
	Training Loss: 0.231553 	Validation Loss: 1.479513

Epoch 40 - 2019-08-05T18:39:33.418680
	Training Loss: 0.230565 	Validation Loss: 1.490898

Epoch 41 - 2019-08-05T18:41:00.827516
	Training Loss: 0.226668 	Validation Loss: 1.488077

Epoch 42 - 2019-08-05T18:42:28.867156
	Training Loss: 0.224077 	Validation Loss: 1.491546

Epoch 43 - 2019-08-05T18:43:57.422331
	Training Loss: 0.220086 	Validation Loss: 1.488671

Epoch 44 - 2019-08-05T18:45:26.309710
	Training Loss: 0.218904 	Validation Loss: 1.478370

Epoch 45 - 2019-08-05T18:46:53.126667
	Training Loss: 0.214222 	Validation Loss: 1.485522

Epoch 46 - 2019-08-05T18:48:21.064785
	Training Loss: 0.212359 	Validation Loss: 1.515655

Epoch 47 - 2019-08-05T18:49:50.387809
	Training Loss: 0.208150 	Validation Loss: 1.500117

Epoch 48 - 2019-08-05T18:51:19.450938
	Training Loss: 0.202900 	Validation Loss: 1.535036

Epoch 49 - 2019-08-05T18:52:46.470176
	Training Loss: 0.197726 	Validation Loss: 1.532591

Epoch 50 - 2019-08-05T18:54:14.439966
	Training Loss: 0.196481 	Validation Loss: 1.551977

Epoch 51 - 2019-08-05T18:55:44.062616
	Training Loss: 0.194547 	Validation Loss: 1.548239

Epoch 52 - 2019-08-05T18:57:14.634449
	Training Loss: 0.188893 	Validation Loss: 1.541900

Epoch 53 - 2019-08-05T18:58:54.795553
	Training Loss: 0.187297 	Validation Loss: 1.563917

Epoch 54 - 2019-08-05T19:00:33.585005
	Training Loss: 0.185713 	Validation Loss: 1.552671

Epoch 55 - 2019-08-05T19:02:05.703297
	Training Loss: 0.176271 	Validation Loss: 1.565675

Epoch 56 - 2019-08-05T19:03:36.409538
	Training Loss: 0.174134 	Validation Loss: 1.580430

Epoch 57 - 2019-08-05T19:05:05.680659
	Training Loss: 0.172852 	Validation Loss: 1.575195

Epoch 58 - 2019-08-05T19:06:36.185495
	Training Loss: 0.170356 	Validation Loss: 1.611370

Epoch 59 - 2019-08-05T19:08:05.027755
	Training Loss: 0.168846 	Validation Loss: 1.567399

Epoch 60 - 2019-08-05T19:09:33.727614
	Training Loss: 0.162577 	Validation Loss: 1.586799

Epoch 61 - 2019-08-05T19:11:01.231274
	Training Loss: 0.159934 	Validation Loss: 1.594726

Epoch 62 - 2019-08-05T19:12:29.352600
	Training Loss: 0.155478 	Validation Loss: 1.636172

Epoch 63 - 2019-08-05T19:13:58.129136
	Training Loss: 0.153438 	Validation Loss: 1.635271

Epoch 64 - 2019-08-05T19:15:28.128279
	Training Loss: 0.148250 	Validation Loss: 1.644653

Epoch 65 - 2019-08-05T19:16:57.373869
	Training Loss: 0.148474 	Validation Loss: 1.626421

Epoch 66 - 2019-08-05T19:18:27.043681
	Training Loss: 0.142463 	Validation Loss: 1.659414

Epoch 67 - 2019-08-05T19:19:55.341209
	Training Loss: 0.142205 	Validation Loss: 1.644669

Epoch 68 - 2019-08-05T19:21:22.477507
	Training Loss: 0.138190 	Validation Loss: 1.674850

Epoch 69 - 2019-08-05T19:22:50.823914
	Training Loss: 0.136762 	Validation Loss: 1.691805

Epoch 70 - 2019-08-05T19:24:20.158024
	Training Loss: 0.131176 	Validation Loss: 1.676654

Epoch 71 - 2019-08-05T19:25:48.984785
	Training Loss: 0.128480 	Validation Loss: 1.738806

Epoch 72 - 2019-08-05T19:27:18.267749
	Training Loss: 0.128170 	Validation Loss: 1.699477

Epoch 73 - 2019-08-05T19:28:45.394298
	Training Loss: 0.126004 	Validation Loss: 1.717563

Epoch 74 - 2019-08-05T19:30:14.590307
	Training Loss: 0.120479 	Validation Loss: 1.702332

Epoch 75 - 2019-08-05T19:31:43.901955
	Training Loss: 0.118896 	Validation Loss: 1.740439

Epoch 76 - 2019-08-05T19:33:11.439210
	Training Loss: 0.114252 	Validation Loss: 1.733989

Epoch 77 - 2019-08-05T19:34:37.758513
	Training Loss: 0.113902 	Validation Loss: 1.819712

Epoch 78 - 2019-08-05T19:36:06.727982
	Training Loss: 0.114528 	Validation Loss: 1.754340

Epoch 79 - 2019-08-05T19:37:34.622449
	Training Loss: 0.108566 	Validation Loss: 1.764231

Epoch 80 - 2019-08-05T19:39:03.717872
	Training Loss: 0.106802 	Validation Loss: 1.752384

Epoch 81 - 2019-08-05T19:40:33.275799
	Training Loss: 0.101496 	Validation Loss: 1.779401

Epoch 82 - 2019-08-05T19:42:01.694881
	Training Loss: 0.100313 	Validation Loss: 1.804820

Epoch 83 - 2019-08-05T19:43:28.157032
	Training Loss: 0.100809 	Validation Loss: 1.808527

Epoch 84 - 2019-08-05T19:44:56.128427
	Training Loss: 0.097156 	Validation Loss: 1.782971

Epoch 85 - 2019-08-05T19:46:22.163925
	Training Loss: 0.093614 	Validation Loss: 1.774720

Epoch 86 - 2019-08-05T19:47:48.218336
	Training Loss: 0.092532 	Validation Loss: 1.880625

Epoch 87 - 2019-08-05T19:49:14.828451
	Training Loss: 0.090424 	Validation Loss: 1.910002

Epoch 88 - 2019-08-05T19:50:46.896718
	Training Loss: 0.090071 	Validation Loss: 1.826997

Epoch 89 - 2019-08-05T19:52:17.004260
	Training Loss: 0.086896 	Validation Loss: 1.861616

Epoch 90 - 2019-08-05T19:53:43.097061
	Training Loss: 0.085692 	Validation Loss: 1.875430

Epoch 91 - 2019-08-05T19:55:09.186004
	Training Loss: 0.081952 	Validation Loss: 1.839614

Epoch 92 - 2019-08-05T19:56:35.298467
	Training Loss: 0.080097 	Validation Loss: 1.914921

Epoch 93 - 2019-08-05T19:58:01.913978
	Training Loss: 0.081673 	Validation Loss: 1.862393

Epoch 94 - 2019-08-05T19:59:27.981291
	Training Loss: 0.078843 	Validation Loss: 1.831258

Epoch 95 - 2019-08-05T20:00:53.993982
	Training Loss: 0.074591 	Validation Loss: 1.884032

Epoch 96 - 2019-08-05T20:02:20.046497
	Training Loss: 0.073444 	Validation Loss: 1.879837

Epoch 97 - 2019-08-05T20:03:46.078979
	Training Loss: 0.073009 	Validation Loss: 1.935481

Epoch 98 - 2019-08-05T20:05:12.143814
	Training Loss: 0.073690 	Validation Loss: 1.845652

Epoch 99 - 2019-08-05T20:06:38.169833
	Training Loss: 0.069176 	Validation Loss: 1.942388

Epoch 100 - 2019-08-05T20:08:04.194153
	Training Loss: 0.069060 	Validation Loss: 1.931240

Epoch 101 - 2019-08-05T20:09:30.236542
	Training Loss: 0.068461 	Validation Loss: 1.923470

Epoch 102 - 2019-08-05T20:10:56.254312
	Training Loss: 0.066814 	Validation Loss: 1.937219

Epoch 103 - 2019-08-05T20:12:22.259792
	Training Loss: 0.060590 	Validation Loss: 1.946246

Epoch 104 - 2019-08-05T20:13:48.309458
	Training Loss: 0.063671 	Validation Loss: 1.946490

Epoch 105 - 2019-08-05T20:15:14.343006
	Training Loss: 0.061257 	Validation Loss: 1.925688

Epoch 106 - 2019-08-05T20:16:40.374432
	Training Loss: 0.060519 	Validation Loss: 1.975619

Epoch 107 - 2019-08-05T20:18:06.399853
	Training Loss: 0.058349 	Validation Loss: 1.952672

Epoch 108 - 2019-08-05T20:19:32.471837
	Training Loss: 0.058680 	Validation Loss: 1.944191

Epoch 109 - 2019-08-05T20:20:58.494339
	Training Loss: 0.056120 	Validation Loss: 1.906518

Epoch 110 - 2019-08-05T20:22:24.503826
	Training Loss: 0.057353 	Validation Loss: 1.929538

Epoch 111 - 2019-08-05T20:23:50.533376
	Training Loss: 0.053740 	Validation Loss: 1.972844

Epoch 112 - 2019-08-05T20:25:16.560574
	Training Loss: 0.053115 	Validation Loss: 1.950815

Epoch 113 - 2019-08-05T20:26:42.564876
	Training Loss: 0.049080 	Validation Loss: 1.997015

Epoch 114 - 2019-08-05T20:28:08.638020
	Training Loss: 0.050158 	Validation Loss: 1.907150

Epoch 115 - 2019-08-05T20:29:34.669179
	Training Loss: 0.048611 	Validation Loss: 1.860226

Epoch 116 - 2019-08-05T20:31:00.713352
	Training Loss: 0.047833 	Validation Loss: 2.014218

Epoch 117 - 2019-08-05T20:32:26.726329
	Training Loss: 0.047525 	Validation Loss: 2.013588

Epoch 118 - 2019-08-05T20:33:52.762650
	Training Loss: 0.046891 	Validation Loss: 1.952544

Epoch 119 - 2019-08-05T20:35:18.776038
	Training Loss: 0.045371 	Validation Loss: 1.926089

Epoch 120 - 2019-08-05T20:36:44.843106
	Training Loss: 0.044465 	Validation Loss: 2.012800

Epoch 121 - 2019-08-05T20:38:10.860673
	Training Loss: 0.046069 	Validation Loss: 1.972273

Epoch 122 - 2019-08-05T20:39:36.895550
	Training Loss: 0.043189 	Validation Loss: 1.972010

Epoch 123 - 2019-08-05T20:41:02.964634
	Training Loss: 0.042251 	Validation Loss: 1.911895

Epoch 124 - 2019-08-05T20:42:28.996834
	Training Loss: 0.041763 	Validation Loss: 1.956250

Epoch 125 - 2019-08-05T20:43:54.997951
	Training Loss: 0.041370 	Validation Loss: 1.979772

Epoch 126 - 2019-08-05T20:45:21.034843
	Training Loss: 0.041726 	Validation Loss: 2.012618

Epoch 127 - 2019-08-05T20:46:47.051296
	Training Loss: 0.039780 	Validation Loss: 1.944580

Epoch 128 - 2019-08-05T20:48:13.071796
	Training Loss: 0.038601 	Validation Loss: 1.856140

Epoch 129 - 2019-08-05T20:49:39.071623
	Training Loss: 0.037639 	Validation Loss: 2.015521

Epoch 130 - 2019-08-05T20:51:05.097792
	Training Loss: 0.038439 	Validation Loss: 1.882037

Epoch 131 - 2019-08-05T20:52:31.143748
	Training Loss: 0.038860 	Validation Loss: 1.989427

Epoch 132 - 2019-08-05T20:53:57.178560
	Training Loss: 0.037814 	Validation Loss: 1.987003

Epoch 133 - 2019-08-05T20:55:23.203169
	Training Loss: 0.036237 	Validation Loss: 1.798144

Epoch 134 - 2019-08-05T20:56:49.219321
	Training Loss: 0.035623 	Validation Loss: 1.923564

Epoch 135 - 2019-08-05T20:58:15.259403
	Training Loss: 0.037021 	Validation Loss: 2.010242

Epoch 136 - 2019-08-05T20:59:41.271702
	Training Loss: 0.034569 	Validation Loss: 1.925526

Epoch 137 - 2019-08-05T21:01:07.298407
	Training Loss: 0.035440 	Validation Loss: 1.898569

Epoch 138 - 2019-08-05T21:02:33.318622
	Training Loss: 0.033005 	Validation Loss: 1.862075

Epoch 139 - 2019-08-05T21:03:59.382884
	Training Loss: 0.034634 	Validation Loss: 1.974075

Epoch 140 - 2019-08-05T21:05:25.401343
	Training Loss: 0.033050 	Validation Loss: 1.893527

Epoch 141 - 2019-08-05T21:06:51.438658
	Training Loss: 0.033203 	Validation Loss: 1.974131

Epoch 142 - 2019-08-05T21:08:17.454374
	Training Loss: 0.032925 	Validation Loss: 1.839819

Epoch 143 - 2019-08-05T21:09:43.437192
	Training Loss: 0.031825 	Validation Loss: 1.879010

Epoch 144 - 2019-08-05T21:11:09.474271
	Training Loss: 0.030512 	Validation Loss: 1.825527

Epoch 145 - 2019-08-05T21:12:35.521529
	Training Loss: 0.029736 	Validation Loss: 1.830145

Epoch 146 - 2019-08-05T21:14:01.575213
	Training Loss: 0.029145 	Validation Loss: 1.756403

Epoch 147 - 2019-08-05T21:15:27.590023
	Training Loss: 0.030270 	Validation Loss: 1.836115

Epoch 148 - 2019-08-05T21:16:53.637946
	Training Loss: 0.028788 	Validation Loss: 1.760330

Epoch 149 - 2019-08-05T21:18:19.663495
	Training Loss: 0.029111 	Validation Loss: 1.973051

Epoch 150 - 2019-08-05T21:19:45.672625
	Training Loss: 0.029473 	Validation Loss: 1.786092

Epoch 151 - 2019-08-05T21:21:11.733028
	Training Loss: 0.027870 	Validation Loss: 1.692589

Epoch 152 - 2019-08-05T21:22:37.739683
	Training Loss: 0.028707 	Validation Loss: 1.817997

Epoch 153 - 2019-08-05T21:24:03.748837
	Training Loss: 0.029220 	Validation Loss: 1.897811

Epoch 154 - 2019-08-05T21:25:29.793627
	Training Loss: 0.029101 	Validation Loss: 1.663165

Epoch 155 - 2019-08-05T21:26:55.793935
	Training Loss: 0.027992 	Validation Loss: 1.685027

Epoch 156 - 2019-08-05T21:28:21.810906
	Training Loss: 0.028092 	Validation Loss: 1.575041

Epoch 157 - 2019-08-05T21:29:47.809043
	Training Loss: 0.027356 	Validation Loss: 1.794381

Epoch 158 - 2019-08-05T21:31:13.841400
	Training Loss: 0.026547 	Validation Loss: 1.914265

Epoch 159 - 2019-08-05T21:32:39.831468
	Training Loss: 0.026886 	Validation Loss: 1.693716

Epoch 160 - 2019-08-05T21:34:05.869290
	Training Loss: 0.026408 	Validation Loss: 1.660368

Epoch 161 - 2019-08-05T21:35:31.850978
	Training Loss: 0.025065 	Validation Loss: 1.599207

Epoch 162 - 2019-08-05T21:36:57.849311
	Training Loss: 0.024618 	Validation Loss: 1.679003

Epoch 163 - 2019-08-05T21:38:23.856471
	Training Loss: 0.025413 	Validation Loss: 1.606857

Epoch 164 - 2019-08-05T21:39:49.870456
	Training Loss: 0.025047 	Validation Loss: 1.778856

Epoch 165 - 2019-08-05T21:41:15.909971
	Training Loss: 0.023373 	Validation Loss: 1.712015

Epoch 166 - 2019-08-05T21:42:41.941135
	Training Loss: 0.022531 	Validation Loss: 1.560255

Epoch 167 - 2019-08-05T21:44:07.989783
	Training Loss: 0.022974 	Validation Loss: 1.640962

Epoch 168 - 2019-08-05T21:45:33.994952
	Training Loss: 0.023261 	Validation Loss: 1.618518

Epoch 169 - 2019-08-05T21:46:59.998478
	Training Loss: 0.024478 	Validation Loss: 1.692163

Epoch 170 - 2019-08-05T21:48:26.020685
	Training Loss: 0.022797 	Validation Loss: 1.598313

Epoch 171 - 2019-08-05T21:49:51.991623
	Training Loss: 0.023127 	Validation Loss: 1.618461

Epoch 172 - 2019-08-05T21:51:18.007438
	Training Loss: 0.021588 	Validation Loss: 1.595350

Epoch 173 - 2019-08-05T21:52:44.024579
	Training Loss: 0.022346 	Validation Loss: 1.498735

Epoch 174 - 2019-08-05T21:54:10.043864
	Training Loss: 0.023319 	Validation Loss: 1.578913

Epoch 175 - 2019-08-05T21:55:36.024772
	Training Loss: 0.022170 	Validation Loss: 1.705685

Epoch 176 - 2019-08-05T21:57:02.057089
	Training Loss: 0.022301 	Validation Loss: 1.584019

Epoch 177 - 2019-08-05T21:58:28.074795
	Training Loss: 0.022244 	Validation Loss: 1.451718
	Validation loss decreased (1.470257 --> 1.451718).  Saving model ...
	Saving the model in path: data/models/2019-08-05T17:41:19.905244.pth

Epoch 178 - 2019-08-05T21:59:55.724144
	Training Loss: 0.022582 	Validation Loss: 1.485675

Epoch 179 - 2019-08-05T22:01:21.712756
	Training Loss: 0.021200 	Validation Loss: 1.326460
	Validation loss decreased (1.451718 --> 1.326460).  Saving model ...
	Saving the model in path: data/models/2019-08-05T17:41:19.905244.pth

Epoch 180 - 2019-08-05T22:02:49.362514
	Training Loss: 0.021216 	Validation Loss: 1.649366

Epoch 181 - 2019-08-05T22:04:15.748382
	Training Loss: 0.022315 	Validation Loss: 1.536785

Epoch 182 - 2019-08-05T22:05:41.713073
	Training Loss: 0.021678 	Validation Loss: 1.508810

Epoch 183 - 2019-08-05T22:07:07.728346
	Training Loss: 0.021881 	Validation Loss: 1.357089

Epoch 184 - 2019-08-05T22:08:33.927825
	Training Loss: 0.020072 	Validation Loss: 1.385543

Epoch 185 - 2019-08-05T22:10:00.184283
	Training Loss: 0.019737 	Validation Loss: 1.380036

Epoch 186 - 2019-08-05T22:11:26.088213
	Training Loss: 0.020476 	Validation Loss: 1.423199

Epoch 187 - 2019-08-05T22:12:51.965737
	Training Loss: 0.020671 	Validation Loss: 1.439072

Epoch 188 - 2019-08-05T22:14:17.841263
	Training Loss: 0.021187 	Validation Loss: 1.309474
	Validation loss decreased (1.326460 --> 1.309474).  Saving model ...
	Saving the model in path: data/models/2019-08-05T17:41:19.905244.pth

Epoch 189 - 2019-08-05T22:15:44.713073
	Training Loss: 0.019731 	Validation Loss: 1.519014

Epoch 190 - 2019-08-05T22:17:10.622685
	Training Loss: 0.019246 	Validation Loss: 1.341086

Epoch 191 - 2019-08-05T22:18:36.536288
	Training Loss: 0.019817 	Validation Loss: 1.337433

Epoch 192 - 2019-08-05T22:20:02.439550
	Training Loss: 0.021112 	Validation Loss: 1.343280

Epoch 193 - 2019-08-05T22:21:28.326682
	Training Loss: 0.018721 	Validation Loss: 1.401920

Epoch 194 - 2019-08-05T22:22:54.365823
	Training Loss: 0.018911 	Validation Loss: 1.312993

Epoch 195 - 2019-08-05T22:24:20.376185
	Training Loss: 0.019495 	Validation Loss: 1.323604

Epoch 196 - 2019-08-05T22:25:46.362215
	Training Loss: 0.019416 	Validation Loss: 1.263117
	Validation loss decreased (1.309474 --> 1.263117).  Saving model ...
	Saving the model in path: data/models/2019-08-05T17:41:19.905244.pth

Epoch 197 - 2019-08-05T22:27:13.418653
	Training Loss: 0.018115 	Validation Loss: 1.172503
	Validation loss decreased (1.263117 --> 1.172503).  Saving model ...
	Saving the model in path: data/models/2019-08-05T17:41:19.905244.pth

Epoch 198 - 2019-08-05T22:28:40.916199
	Training Loss: 0.016900 	Validation Loss: 1.234694

Epoch 199 - 2019-08-05T22:30:09.722465
	Training Loss: 0.018256 	Validation Loss: 1.168811
	Validation loss decreased (1.172503 --> 1.168811).  Saving model ...
	Saving the model in path: data/models/2019-08-05T17:41:19.905244.pth

Epoch 200 - 2019-08-05T22:31:42.416772
	Training Loss: 0.017862 	Validation Loss: 1.252823

Training elapsed time: 04:54:14.19
