================================================
Source folder images: RGB/oversampling/
Freezing until layer: 30
Number of epochs: 500
Batch size: 32
Training on GPU: True
================================================
Train: 5664 samples
	Stress: 2812 (49.65%)
	Neutral: 2852 (50.35%)
Validation: 1416 samples
	Stress: 706 (49.86%)
	Neutral: 710 (50.14%)
Test: 1770 samples
	Stress: 882 (49.83%)
	Neutral: 888 (50.17%)
================================================
N epochs: 500

Epoch 1 - 2019-08-06T07:00:22.659702
	Training Loss: 0.120074 	Validation Loss: 2.333270
	Validation loss decreased (inf --> 2.333270).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 2 - 2019-08-06T07:01:48.943757
	Training Loss: 0.188835 	Validation Loss: 2.255637
	Validation loss decreased (2.333270 --> 2.255637).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 3 - 2019-08-06T07:03:15.458765
	Training Loss: 0.194491 	Validation Loss: 2.168680
	Validation loss decreased (2.255637 --> 2.168680).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 4 - 2019-08-06T07:04:42.203471
	Training Loss: 0.201991 	Validation Loss: 2.093031
	Validation loss decreased (2.168680 --> 2.093031).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 5 - 2019-08-06T07:06:09.058684
	Training Loss: 0.207512 	Validation Loss: 2.039098
	Validation loss decreased (2.093031 --> 2.039098).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 6 - 2019-08-06T07:07:35.622332
	Training Loss: 0.212955 	Validation Loss: 1.980605
	Validation loss decreased (2.039098 --> 1.980605).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 7 - 2019-08-06T07:09:02.232955
	Training Loss: 0.219387 	Validation Loss: 1.926488
	Validation loss decreased (1.980605 --> 1.926488).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 8 - 2019-08-06T07:10:29.987883
	Training Loss: 0.222104 	Validation Loss: 1.886759
	Validation loss decreased (1.926488 --> 1.886759).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 9 - 2019-08-06T07:11:57.115515
	Training Loss: 0.231197 	Validation Loss: 1.834092
	Validation loss decreased (1.886759 --> 1.834092).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 10 - 2019-08-06T07:13:23.695461
	Training Loss: 0.236272 	Validation Loss: 1.785323
	Validation loss decreased (1.834092 --> 1.785323).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 11 - 2019-08-06T07:14:50.323620
	Training Loss: 0.239727 	Validation Loss: 1.768492
	Validation loss decreased (1.785323 --> 1.768492).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 12 - 2019-08-06T07:16:16.969056
	Training Loss: 0.243999 	Validation Loss: 1.725311
	Validation loss decreased (1.768492 --> 1.725311).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 13 - 2019-08-06T07:17:43.527585
	Training Loss: 0.246080 	Validation Loss: 1.699502
	Validation loss decreased (1.725311 --> 1.699502).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 14 - 2019-08-06T07:19:10.033336
	Training Loss: 0.249403 	Validation Loss: 1.675972
	Validation loss decreased (1.699502 --> 1.675972).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 15 - 2019-08-06T07:20:36.664953
	Training Loss: 0.251837 	Validation Loss: 1.643194
	Validation loss decreased (1.675972 --> 1.643194).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 16 - 2019-08-06T07:22:03.170217
	Training Loss: 0.253952 	Validation Loss: 1.628641
	Validation loss decreased (1.643194 --> 1.628641).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 17 - 2019-08-06T07:23:29.664774
	Training Loss: 0.254664 	Validation Loss: 1.607262
	Validation loss decreased (1.628641 --> 1.607262).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 18 - 2019-08-06T07:24:56.200470
	Training Loss: 0.255617 	Validation Loss: 1.589343
	Validation loss decreased (1.607262 --> 1.589343).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 19 - 2019-08-06T07:26:22.740426
	Training Loss: 0.258407 	Validation Loss: 1.580489
	Validation loss decreased (1.589343 --> 1.580489).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 20 - 2019-08-06T07:27:49.229039
	Training Loss: 0.259690 	Validation Loss: 1.539481
	Validation loss decreased (1.580489 --> 1.539481).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 21 - 2019-08-06T07:29:15.731080
	Training Loss: 0.257266 	Validation Loss: 1.533780
	Validation loss decreased (1.539481 --> 1.533780).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 22 - 2019-08-06T07:30:42.227682
	Training Loss: 0.258868 	Validation Loss: 1.538397

Epoch 23 - 2019-08-06T07:32:07.832503
	Training Loss: 0.258325 	Validation Loss: 1.514786
	Validation loss decreased (1.533780 --> 1.514786).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 24 - 2019-08-06T07:33:34.310729
	Training Loss: 0.255615 	Validation Loss: 1.511564
	Validation loss decreased (1.514786 --> 1.511564).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 25 - 2019-08-06T07:35:00.790722
	Training Loss: 0.256268 	Validation Loss: 1.518061

Epoch 26 - 2019-08-06T07:36:26.422046
	Training Loss: 0.258068 	Validation Loss: 1.488369
	Validation loss decreased (1.511564 --> 1.488369).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 27 - 2019-08-06T07:37:52.929790
	Training Loss: 0.255727 	Validation Loss: 1.502894

Epoch 28 - 2019-08-06T07:39:18.547701
	Training Loss: 0.254310 	Validation Loss: 1.472268
	Validation loss decreased (1.488369 --> 1.472268).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 29 - 2019-08-06T07:40:45.042463
	Training Loss: 0.254048 	Validation Loss: 1.481209

Epoch 30 - 2019-08-06T07:42:10.630799
	Training Loss: 0.252960 	Validation Loss: 1.472065
	Validation loss decreased (1.472268 --> 1.472065).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 31 - 2019-08-06T07:43:37.141943
	Training Loss: 0.249034 	Validation Loss: 1.476878

Epoch 32 - 2019-08-06T07:45:02.750126
	Training Loss: 0.248789 	Validation Loss: 1.467608
	Validation loss decreased (1.472065 --> 1.467608).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 33 - 2019-08-06T07:46:29.250054
	Training Loss: 0.247056 	Validation Loss: 1.463036
	Validation loss decreased (1.467608 --> 1.463036).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 34 - 2019-08-06T07:47:55.748687
	Training Loss: 0.244436 	Validation Loss: 1.471276

Epoch 35 - 2019-08-06T07:49:21.359791
	Training Loss: 0.241692 	Validation Loss: 1.444989
	Validation loss decreased (1.463036 --> 1.444989).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 36 - 2019-08-06T07:50:47.868446
	Training Loss: 0.238141 	Validation Loss: 1.475051

Epoch 37 - 2019-08-06T07:52:13.488593
	Training Loss: 0.238887 	Validation Loss: 1.482861

Epoch 38 - 2019-08-06T07:53:39.080702
	Training Loss: 0.238965 	Validation Loss: 1.458734

Epoch 39 - 2019-08-06T07:55:04.715692
	Training Loss: 0.234495 	Validation Loss: 1.467150

Epoch 40 - 2019-08-06T07:56:30.311182
	Training Loss: 0.229507 	Validation Loss: 1.472556

Epoch 41 - 2019-08-06T07:57:55.904902
	Training Loss: 0.224810 	Validation Loss: 1.484614

Epoch 42 - 2019-08-06T07:59:21.503726
	Training Loss: 0.222993 	Validation Loss: 1.490503

Epoch 43 - 2019-08-06T08:00:47.091292
	Training Loss: 0.219120 	Validation Loss: 1.497668

Epoch 44 - 2019-08-06T08:02:12.707244
	Training Loss: 0.214383 	Validation Loss: 1.488756

Epoch 45 - 2019-08-06T08:03:38.319833
	Training Loss: 0.212788 	Validation Loss: 1.506214

Epoch 46 - 2019-08-06T08:05:03.922828
	Training Loss: 0.209376 	Validation Loss: 1.500035

Epoch 47 - 2019-08-06T08:06:29.531699
	Training Loss: 0.208932 	Validation Loss: 1.509535

Epoch 48 - 2019-08-06T08:07:55.110544
	Training Loss: 0.205078 	Validation Loss: 1.497990

Epoch 49 - 2019-08-06T08:09:20.711743
	Training Loss: 0.204515 	Validation Loss: 1.513091

Epoch 50 - 2019-08-06T08:10:46.307372
	Training Loss: 0.195611 	Validation Loss: 1.517255

Epoch 51 - 2019-08-06T08:12:11.907998
	Training Loss: 0.196388 	Validation Loss: 1.506214

Epoch 52 - 2019-08-06T08:13:37.524393
	Training Loss: 0.192308 	Validation Loss: 1.510891

Epoch 53 - 2019-08-06T08:15:03.144158
	Training Loss: 0.187624 	Validation Loss: 1.540932

Epoch 54 - 2019-08-06T08:16:28.735909
	Training Loss: 0.186210 	Validation Loss: 1.525826

Epoch 55 - 2019-08-06T08:17:54.366296
	Training Loss: 0.181575 	Validation Loss: 1.539733

Epoch 56 - 2019-08-06T08:19:19.993588
	Training Loss: 0.179601 	Validation Loss: 1.569622

Epoch 57 - 2019-08-06T08:20:45.593412
	Training Loss: 0.176700 	Validation Loss: 1.548948

Epoch 58 - 2019-08-06T08:22:11.198916
	Training Loss: 0.172475 	Validation Loss: 1.555605

Epoch 59 - 2019-08-06T08:23:36.831997
	Training Loss: 0.169306 	Validation Loss: 1.552950

Epoch 60 - 2019-08-06T08:25:02.434828
	Training Loss: 0.162120 	Validation Loss: 1.573221

Epoch 61 - 2019-08-06T08:26:28.043668
	Training Loss: 0.161523 	Validation Loss: 1.592312

Epoch 62 - 2019-08-06T08:27:53.694407
	Training Loss: 0.160216 	Validation Loss: 1.609164

Epoch 63 - 2019-08-06T08:29:19.309162
	Training Loss: 0.154267 	Validation Loss: 1.590958

Epoch 64 - 2019-08-06T08:30:44.924438
	Training Loss: 0.151523 	Validation Loss: 1.581754

Epoch 65 - 2019-08-06T08:32:10.531771
	Training Loss: 0.148796 	Validation Loss: 1.600337

Epoch 66 - 2019-08-06T08:33:36.144892
	Training Loss: 0.144049 	Validation Loss: 1.638487

Epoch 67 - 2019-08-06T08:35:01.761868
	Training Loss: 0.143604 	Validation Loss: 1.646457

Epoch 68 - 2019-08-06T08:36:27.380139
	Training Loss: 0.140749 	Validation Loss: 1.688523

Epoch 69 - 2019-08-06T08:37:53.000899
	Training Loss: 0.139437 	Validation Loss: 1.650586

Epoch 70 - 2019-08-06T08:39:18.623881
	Training Loss: 0.136702 	Validation Loss: 1.658924

Epoch 71 - 2019-08-06T08:40:44.217729
	Training Loss: 0.134360 	Validation Loss: 1.672846

Epoch 72 - 2019-08-06T08:42:09.821841
	Training Loss: 0.131164 	Validation Loss: 1.658661

Epoch 73 - 2019-08-06T08:43:35.471777
	Training Loss: 0.127415 	Validation Loss: 1.695982

Epoch 74 - 2019-08-06T08:45:01.092827
	Training Loss: 0.123957 	Validation Loss: 1.685443

Epoch 75 - 2019-08-06T08:46:26.711809
	Training Loss: 0.121894 	Validation Loss: 1.655268

Epoch 76 - 2019-08-06T08:47:52.311099
	Training Loss: 0.116548 	Validation Loss: 1.737381

Epoch 77 - 2019-08-06T08:49:17.938559
	Training Loss: 0.115843 	Validation Loss: 1.733493

Epoch 78 - 2019-08-06T08:50:43.542341
	Training Loss: 0.112797 	Validation Loss: 1.712329

Epoch 79 - 2019-08-06T08:52:09.134301
	Training Loss: 0.110357 	Validation Loss: 1.753581

Epoch 80 - 2019-08-06T08:53:34.757856
	Training Loss: 0.107133 	Validation Loss: 1.740836

Epoch 81 - 2019-08-06T08:55:00.359943
	Training Loss: 0.104610 	Validation Loss: 1.715236

Epoch 82 - 2019-08-06T08:56:25.967389
	Training Loss: 0.101608 	Validation Loss: 1.789742

Epoch 83 - 2019-08-06T08:57:51.558128
	Training Loss: 0.105704 	Validation Loss: 1.815808

Epoch 84 - 2019-08-06T08:59:17.192762
	Training Loss: 0.103297 	Validation Loss: 1.818339

Epoch 85 - 2019-08-06T09:00:42.846344
	Training Loss: 0.099635 	Validation Loss: 1.789666

Epoch 86 - 2019-08-06T09:02:08.444793
	Training Loss: 0.095099 	Validation Loss: 1.776611

Epoch 87 - 2019-08-06T09:03:34.037207
	Training Loss: 0.092533 	Validation Loss: 1.791965

Epoch 88 - 2019-08-06T09:04:59.646239
	Training Loss: 0.093439 	Validation Loss: 1.787431

Epoch 89 - 2019-08-06T09:06:25.265640
	Training Loss: 0.087428 	Validation Loss: 1.764050

Epoch 90 - 2019-08-06T09:07:50.860217
	Training Loss: 0.086380 	Validation Loss: 1.831328

Epoch 91 - 2019-08-06T09:09:16.459943
	Training Loss: 0.084128 	Validation Loss: 1.857009

Epoch 92 - 2019-08-06T09:10:42.074121
	Training Loss: 0.081370 	Validation Loss: 1.904595

Epoch 93 - 2019-08-06T09:12:07.715997
	Training Loss: 0.080471 	Validation Loss: 1.759576

Epoch 94 - 2019-08-06T09:13:33.345643
	Training Loss: 0.077453 	Validation Loss: 1.840638

Epoch 95 - 2019-08-06T09:14:58.998013
	Training Loss: 0.074582 	Validation Loss: 1.838497

Epoch 96 - 2019-08-06T09:16:24.619793
	Training Loss: 0.076474 	Validation Loss: 1.887083

Epoch 97 - 2019-08-06T09:17:50.279160
	Training Loss: 0.072766 	Validation Loss: 1.821222

Epoch 98 - 2019-08-06T09:19:15.932892
	Training Loss: 0.070590 	Validation Loss: 1.881765

Epoch 99 - 2019-08-06T09:20:41.563939
	Training Loss: 0.069582 	Validation Loss: 1.874405

Epoch 100 - 2019-08-06T09:22:07.181773
	Training Loss: 0.069518 	Validation Loss: 1.859068

Epoch 101 - 2019-08-06T09:23:32.791534
	Training Loss: 0.068018 	Validation Loss: 1.876495

Epoch 102 - 2019-08-06T09:24:58.445301
	Training Loss: 0.068365 	Validation Loss: 1.894831

Epoch 103 - 2019-08-06T09:26:24.075649
	Training Loss: 0.064529 	Validation Loss: 1.854564

Epoch 104 - 2019-08-06T09:27:49.703396
	Training Loss: 0.065829 	Validation Loss: 1.921519

Epoch 105 - 2019-08-06T09:29:15.357860
	Training Loss: 0.063483 	Validation Loss: 1.917147

Epoch 106 - 2019-08-06T09:30:41.005808
	Training Loss: 0.062215 	Validation Loss: 1.861529

Epoch 107 - 2019-08-06T09:32:06.672456
	Training Loss: 0.060763 	Validation Loss: 1.949377

Epoch 108 - 2019-08-06T09:33:32.279331
	Training Loss: 0.059169 	Validation Loss: 1.963009

Epoch 109 - 2019-08-06T09:34:57.913455
	Training Loss: 0.057290 	Validation Loss: 1.866813

Epoch 110 - 2019-08-06T09:36:23.541569
	Training Loss: 0.057106 	Validation Loss: 1.944999

Epoch 111 - 2019-08-06T09:37:49.157180
	Training Loss: 0.055842 	Validation Loss: 1.922415

Epoch 112 - 2019-08-06T09:39:14.803677
	Training Loss: 0.053450 	Validation Loss: 2.048486

Epoch 113 - 2019-08-06T09:40:40.424476
	Training Loss: 0.053164 	Validation Loss: 1.893160

Epoch 114 - 2019-08-06T09:42:06.053221
	Training Loss: 0.052417 	Validation Loss: 1.909483

Epoch 115 - 2019-08-06T09:43:31.657172
	Training Loss: 0.050741 	Validation Loss: 1.900299

Epoch 116 - 2019-08-06T09:44:57.271837
	Training Loss: 0.050449 	Validation Loss: 1.891678

Epoch 117 - 2019-08-06T09:46:22.900406
	Training Loss: 0.047164 	Validation Loss: 1.831065

Epoch 118 - 2019-08-06T09:47:48.505297
	Training Loss: 0.046994 	Validation Loss: 1.934645

Epoch 119 - 2019-08-06T09:49:14.139089
	Training Loss: 0.047930 	Validation Loss: 1.911500

Epoch 120 - 2019-08-06T09:50:39.752083
	Training Loss: 0.045257 	Validation Loss: 1.805545

Epoch 121 - 2019-08-06T09:52:05.344601
	Training Loss: 0.045277 	Validation Loss: 2.002051

Epoch 122 - 2019-08-06T09:53:30.969820
	Training Loss: 0.044766 	Validation Loss: 1.850016

Epoch 123 - 2019-08-06T09:54:56.582076
	Training Loss: 0.042767 	Validation Loss: 1.939857

Epoch 124 - 2019-08-06T09:56:22.209568
	Training Loss: 0.042625 	Validation Loss: 1.893012

Epoch 125 - 2019-08-06T09:57:47.844478
	Training Loss: 0.042643 	Validation Loss: 1.802313

Epoch 126 - 2019-08-06T09:59:13.476709
	Training Loss: 0.042741 	Validation Loss: 1.914418

Epoch 127 - 2019-08-06T10:00:39.103866
	Training Loss: 0.040743 	Validation Loss: 1.916373

Epoch 128 - 2019-08-06T10:02:04.743483
	Training Loss: 0.038554 	Validation Loss: 1.861708

Epoch 129 - 2019-08-06T10:03:30.360373
	Training Loss: 0.037791 	Validation Loss: 1.805464

Epoch 130 - 2019-08-06T10:04:55.994881
	Training Loss: 0.037091 	Validation Loss: 1.863391

Epoch 131 - 2019-08-06T10:06:21.602830
	Training Loss: 0.039189 	Validation Loss: 1.987907

Epoch 132 - 2019-08-06T10:07:47.225723
	Training Loss: 0.036415 	Validation Loss: 1.820506

Epoch 133 - 2019-08-06T10:09:12.838567
	Training Loss: 0.037022 	Validation Loss: 1.834019

Epoch 134 - 2019-08-06T10:10:38.466524
	Training Loss: 0.036254 	Validation Loss: 1.868659

Epoch 135 - 2019-08-06T10:12:04.108803
	Training Loss: 0.035718 	Validation Loss: 1.931382

Epoch 136 - 2019-08-06T10:13:29.740742
	Training Loss: 0.035441 	Validation Loss: 1.957840

Epoch 137 - 2019-08-06T10:14:55.363592
	Training Loss: 0.035857 	Validation Loss: 1.792691

Epoch 138 - 2019-08-06T10:16:20.992464
	Training Loss: 0.032727 	Validation Loss: 1.764889

Epoch 139 - 2019-08-06T10:17:46.621113
	Training Loss: 0.034785 	Validation Loss: 1.854681

Epoch 140 - 2019-08-06T10:19:12.241280
	Training Loss: 0.033547 	Validation Loss: 1.809085

Epoch 141 - 2019-08-06T10:20:37.895303
	Training Loss: 0.032299 	Validation Loss: 1.797856

Epoch 142 - 2019-08-06T10:22:03.534315
	Training Loss: 0.030305 	Validation Loss: 1.849811

Epoch 143 - 2019-08-06T10:23:29.143722
	Training Loss: 0.032158 	Validation Loss: 1.820533

Epoch 144 - 2019-08-06T10:24:54.781806
	Training Loss: 0.031638 	Validation Loss: 1.747955

Epoch 145 - 2019-08-06T10:26:20.401218
	Training Loss: 0.031406 	Validation Loss: 1.865250

Epoch 146 - 2019-08-06T10:27:46.017142
	Training Loss: 0.030197 	Validation Loss: 1.778722

Epoch 147 - 2019-08-06T10:29:11.631771
	Training Loss: 0.028678 	Validation Loss: 1.770591

Epoch 148 - 2019-08-06T10:30:37.234474
	Training Loss: 0.028795 	Validation Loss: 1.775985

Epoch 149 - 2019-08-06T10:32:02.870164
	Training Loss: 0.028787 	Validation Loss: 1.730962

Epoch 150 - 2019-08-06T10:33:28.519162
	Training Loss: 0.028334 	Validation Loss: 1.758852

Epoch 151 - 2019-08-06T10:34:54.136343
	Training Loss: 0.029503 	Validation Loss: 1.762533

Epoch 152 - 2019-08-06T10:36:19.759353
	Training Loss: 0.027656 	Validation Loss: 1.806626

Epoch 153 - 2019-08-06T10:37:45.355610
	Training Loss: 0.028298 	Validation Loss: 1.802489

Epoch 154 - 2019-08-06T10:39:10.964400
	Training Loss: 0.026951 	Validation Loss: 1.741868

Epoch 155 - 2019-08-06T10:40:36.577807
	Training Loss: 0.028525 	Validation Loss: 1.611735

Epoch 156 - 2019-08-06T10:42:02.188113
	Training Loss: 0.027781 	Validation Loss: 1.638276

Epoch 157 - 2019-08-06T10:43:27.837466
	Training Loss: 0.026871 	Validation Loss: 1.612788

Epoch 158 - 2019-08-06T10:44:53.456712
	Training Loss: 0.026127 	Validation Loss: 1.821215

Epoch 159 - 2019-08-06T10:46:19.097178
	Training Loss: 0.028105 	Validation Loss: 1.710532

Epoch 160 - 2019-08-06T10:47:44.736675
	Training Loss: 0.027781 	Validation Loss: 1.616066

Epoch 161 - 2019-08-06T10:49:10.365771
	Training Loss: 0.025827 	Validation Loss: 1.675604

Epoch 162 - 2019-08-06T10:50:35.999178
	Training Loss: 0.025676 	Validation Loss: 1.760258

Epoch 163 - 2019-08-06T10:52:01.653033
	Training Loss: 0.024614 	Validation Loss: 1.649124

Epoch 164 - 2019-08-06T10:53:27.275201
	Training Loss: 0.024540 	Validation Loss: 1.577371

Epoch 165 - 2019-08-06T10:54:52.883577
	Training Loss: 0.024860 	Validation Loss: 1.645377

Epoch 166 - 2019-08-06T10:56:18.489372
	Training Loss: 0.024819 	Validation Loss: 1.711402

Epoch 167 - 2019-08-06T10:57:44.134840
	Training Loss: 0.024599 	Validation Loss: 1.535501

Epoch 168 - 2019-08-06T10:59:09.767304
	Training Loss: 0.024753 	Validation Loss: 1.565771

Epoch 169 - 2019-08-06T11:00:35.399919
	Training Loss: 0.024107 	Validation Loss: 1.585272

Epoch 170 - 2019-08-06T11:02:01.052738
	Training Loss: 0.023099 	Validation Loss: 1.574597

Epoch 171 - 2019-08-06T11:03:26.666155
	Training Loss: 0.023494 	Validation Loss: 1.620974

Epoch 172 - 2019-08-06T11:04:52.285965
	Training Loss: 0.023472 	Validation Loss: 1.595186

Epoch 173 - 2019-08-06T11:06:17.897547
	Training Loss: 0.023266 	Validation Loss: 1.765782

Epoch 174 - 2019-08-06T11:07:43.521177
	Training Loss: 0.022582 	Validation Loss: 1.518424

Epoch 175 - 2019-08-06T11:09:09.160458
	Training Loss: 0.022637 	Validation Loss: 1.441137
	Validation loss decreased (1.444989 --> 1.441137).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 176 - 2019-08-06T11:10:35.674072
	Training Loss: 0.023953 	Validation Loss: 1.492959

Epoch 177 - 2019-08-06T11:12:01.308520
	Training Loss: 0.022471 	Validation Loss: 1.385503
	Validation loss decreased (1.441137 --> 1.385503).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 178 - 2019-08-06T11:13:27.960076
	Training Loss: 0.022268 	Validation Loss: 1.438085

Epoch 179 - 2019-08-06T11:14:53.583950
	Training Loss: 0.021619 	Validation Loss: 1.452300

Epoch 180 - 2019-08-06T11:16:19.213437
	Training Loss: 0.022543 	Validation Loss: 1.433176

Epoch 181 - 2019-08-06T11:17:44.851323
	Training Loss: 0.021826 	Validation Loss: 1.551762

Epoch 182 - 2019-08-06T11:19:10.517172
	Training Loss: 0.020692 	Validation Loss: 1.394412

Epoch 183 - 2019-08-06T11:20:36.189365
	Training Loss: 0.021716 	Validation Loss: 1.369934
	Validation loss decreased (1.385503 --> 1.369934).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 184 - 2019-08-06T11:22:02.817621
	Training Loss: 0.021406 	Validation Loss: 1.395645

Epoch 185 - 2019-08-06T11:23:28.504035
	Training Loss: 0.022113 	Validation Loss: 1.391105

Epoch 186 - 2019-08-06T11:24:54.154412
	Training Loss: 0.022037 	Validation Loss: 1.410575

Epoch 187 - 2019-08-06T11:26:19.799402
	Training Loss: 0.021510 	Validation Loss: 1.391732

Epoch 188 - 2019-08-06T11:27:45.406018
	Training Loss: 0.020794 	Validation Loss: 1.440157

Epoch 189 - 2019-08-06T11:29:11.055826
	Training Loss: 0.021449 	Validation Loss: 1.454159

Epoch 190 - 2019-08-06T11:30:36.674564
	Training Loss: 0.021060 	Validation Loss: 1.441010

Epoch 191 - 2019-08-06T11:32:02.344060
	Training Loss: 0.020096 	Validation Loss: 1.285440
	Validation loss decreased (1.369934 --> 1.285440).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 192 - 2019-08-06T11:33:28.894121
	Training Loss: 0.020562 	Validation Loss: 1.362474

Epoch 193 - 2019-08-06T11:34:54.534084
	Training Loss: 0.019629 	Validation Loss: 1.230062
	Validation loss decreased (1.285440 --> 1.230062).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 194 - 2019-08-06T11:36:21.074964
	Training Loss: 0.020804 	Validation Loss: 1.336788

Epoch 195 - 2019-08-06T11:37:46.695077
	Training Loss: 0.021099 	Validation Loss: 1.283906

Epoch 196 - 2019-08-06T11:39:12.307824
	Training Loss: 0.020926 	Validation Loss: 1.450941

Epoch 197 - 2019-08-06T11:40:37.918288
	Training Loss: 0.021070 	Validation Loss: 1.173880
	Validation loss decreased (1.230062 --> 1.173880).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 198 - 2019-08-06T11:42:04.447072
	Training Loss: 0.019564 	Validation Loss: 1.222935

Epoch 199 - 2019-08-06T11:43:30.101222
	Training Loss: 0.019367 	Validation Loss: 1.301890

Epoch 200 - 2019-08-06T11:44:55.741540
	Training Loss: 0.019444 	Validation Loss: 1.270895

Epoch 201 - 2019-08-06T11:46:21.394368
	Training Loss: 0.018578 	Validation Loss: 1.187691

Epoch 202 - 2019-08-06T11:47:47.044531
	Training Loss: 0.019014 	Validation Loss: 1.123951
	Validation loss decreased (1.173880 --> 1.123951).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 203 - 2019-08-06T11:49:13.579626
	Training Loss: 0.017442 	Validation Loss: 1.160838

Epoch 204 - 2019-08-06T11:50:39.211659
	Training Loss: 0.017737 	Validation Loss: 1.250299

Epoch 205 - 2019-08-06T11:52:04.859629
	Training Loss: 0.019437 	Validation Loss: 1.309006

Epoch 206 - 2019-08-06T11:53:30.496736
	Training Loss: 0.017809 	Validation Loss: 1.147214

Epoch 207 - 2019-08-06T11:54:56.158564
	Training Loss: 0.017617 	Validation Loss: 1.142509

Epoch 208 - 2019-08-06T11:56:21.833296
	Training Loss: 0.017376 	Validation Loss: 1.135163

Epoch 209 - 2019-08-06T11:57:47.487639
	Training Loss: 0.017239 	Validation Loss: 1.058073
	Validation loss decreased (1.123951 --> 1.058073).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 210 - 2019-08-06T11:59:14.038863
	Training Loss: 0.018256 	Validation Loss: 1.207999

Epoch 211 - 2019-08-06T12:00:39.699085
	Training Loss: 0.018154 	Validation Loss: 1.213128

Epoch 212 - 2019-08-06T12:02:05.325708
	Training Loss: 0.017974 	Validation Loss: 1.219453

Epoch 213 - 2019-08-06T12:03:30.947618
	Training Loss: 0.018420 	Validation Loss: 1.142041

Epoch 214 - 2019-08-06T12:04:56.568914
	Training Loss: 0.016957 	Validation Loss: 1.089933

Epoch 215 - 2019-08-06T12:06:22.195496
	Training Loss: 0.018214 	Validation Loss: 1.139816

Epoch 216 - 2019-08-06T12:07:47.823983
	Training Loss: 0.017259 	Validation Loss: 0.947359
	Validation loss decreased (1.058073 --> 0.947359).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 217 - 2019-08-06T12:09:14.403349
	Training Loss: 0.017166 	Validation Loss: 0.997840

Epoch 218 - 2019-08-06T12:10:40.030315
	Training Loss: 0.017910 	Validation Loss: 1.185535

Epoch 219 - 2019-08-06T12:12:05.672071
	Training Loss: 0.017261 	Validation Loss: 1.077894

Epoch 220 - 2019-08-06T12:13:31.304545
	Training Loss: 0.015674 	Validation Loss: 1.022365

Epoch 221 - 2019-08-06T12:14:56.919215
	Training Loss: 0.017025 	Validation Loss: 1.028588

Epoch 222 - 2019-08-06T12:16:22.573253
	Training Loss: 0.016232 	Validation Loss: 1.014033

Epoch 223 - 2019-08-06T12:17:48.205787
	Training Loss: 0.016126 	Validation Loss: 0.990047

Epoch 224 - 2019-08-06T12:19:13.828359
	Training Loss: 0.015572 	Validation Loss: 0.941376
	Validation loss decreased (0.947359 --> 0.941376).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 225 - 2019-08-06T12:20:40.353051
	Training Loss: 0.016362 	Validation Loss: 0.997592

Epoch 226 - 2019-08-06T12:22:05.965238
	Training Loss: 0.016435 	Validation Loss: 0.938250
	Validation loss decreased (0.941376 --> 0.938250).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 227 - 2019-08-06T12:23:32.483094
	Training Loss: 0.016528 	Validation Loss: 0.969485

Epoch 228 - 2019-08-06T12:24:58.096656
	Training Loss: 0.016712 	Validation Loss: 0.902054
	Validation loss decreased (0.938250 --> 0.902054).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 229 - 2019-08-06T12:26:24.659920
	Training Loss: 0.016177 	Validation Loss: 0.817755
	Validation loss decreased (0.902054 --> 0.817755).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 230 - 2019-08-06T12:27:51.172218
	Training Loss: 0.014336 	Validation Loss: 0.796508
	Validation loss decreased (0.817755 --> 0.796508).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 231 - 2019-08-06T12:29:17.702102
	Training Loss: 0.016317 	Validation Loss: 0.877264

Epoch 232 - 2019-08-06T12:30:43.320701
	Training Loss: 0.015036 	Validation Loss: 0.845007

Epoch 233 - 2019-08-06T12:32:08.942764
	Training Loss: 0.015759 	Validation Loss: 0.934899

Epoch 234 - 2019-08-06T12:33:34.553392
	Training Loss: 0.016136 	Validation Loss: 0.867758

Epoch 235 - 2019-08-06T12:35:00.164002
	Training Loss: 0.015465 	Validation Loss: 0.829265

Epoch 236 - 2019-08-06T12:36:25.811120
	Training Loss: 0.016073 	Validation Loss: 0.941426

Epoch 237 - 2019-08-06T12:37:51.420902
	Training Loss: 0.014652 	Validation Loss: 0.765495
	Validation loss decreased (0.796508 --> 0.765495).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 238 - 2019-08-06T12:39:17.942405
	Training Loss: 0.015335 	Validation Loss: 0.763374
	Validation loss decreased (0.765495 --> 0.763374).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 239 - 2019-08-06T12:40:44.454686
	Training Loss: 0.014594 	Validation Loss: 0.737047
	Validation loss decreased (0.763374 --> 0.737047).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 240 - 2019-08-06T12:42:10.937273
	Training Loss: 0.015643 	Validation Loss: 0.930712

Epoch 241 - 2019-08-06T12:43:36.551525
	Training Loss: 0.014190 	Validation Loss: 0.807585

Epoch 242 - 2019-08-06T12:45:02.131839
	Training Loss: 0.013651 	Validation Loss: 0.793646

Epoch 243 - 2019-08-06T12:46:27.741076
	Training Loss: 0.013840 	Validation Loss: 0.658358
	Validation loss decreased (0.737047 --> 0.658358).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 244 - 2019-08-06T12:47:54.239888
	Training Loss: 0.013994 	Validation Loss: 0.830324

Epoch 245 - 2019-08-06T12:49:19.899432
	Training Loss: 0.014995 	Validation Loss: 0.741233

Epoch 246 - 2019-08-06T12:50:45.516168
	Training Loss: 0.013954 	Validation Loss: 0.747680

Epoch 247 - 2019-08-06T12:52:11.133371
	Training Loss: 0.015365 	Validation Loss: 0.863028

Epoch 248 - 2019-08-06T12:53:36.736690
	Training Loss: 0.013369 	Validation Loss: 0.671783

Epoch 249 - 2019-08-06T12:55:02.398379
	Training Loss: 0.013861 	Validation Loss: 0.760543

Epoch 250 - 2019-08-06T12:56:28.009012
	Training Loss: 0.014469 	Validation Loss: 0.717371

Epoch 251 - 2019-08-06T12:57:53.613368
	Training Loss: 0.013672 	Validation Loss: 0.638921
	Validation loss decreased (0.658358 --> 0.638921).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 252 - 2019-08-06T12:59:20.130981
	Training Loss: 0.013793 	Validation Loss: 0.698701

Epoch 253 - 2019-08-06T13:00:45.752135
	Training Loss: 0.014468 	Validation Loss: 0.753193

Epoch 254 - 2019-08-06T13:02:11.373026
	Training Loss: 0.013391 	Validation Loss: 0.682014

Epoch 255 - 2019-08-06T13:03:36.988876
	Training Loss: 0.013512 	Validation Loss: 0.687896

Epoch 256 - 2019-08-06T13:05:02.611569
	Training Loss: 0.014066 	Validation Loss: 0.688895

Epoch 257 - 2019-08-06T13:06:28.172841
	Training Loss: 0.013062 	Validation Loss: 0.597366
	Validation loss decreased (0.638921 --> 0.597366).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 258 - 2019-08-06T13:07:54.685558
	Training Loss: 0.013560 	Validation Loss: 0.665308

Epoch 259 - 2019-08-06T13:09:20.293724
	Training Loss: 0.013030 	Validation Loss: 0.611091

Epoch 260 - 2019-08-06T13:10:45.911117
	Training Loss: 0.012616 	Validation Loss: 0.674705

Epoch 261 - 2019-08-06T13:12:11.534501
	Training Loss: 0.013233 	Validation Loss: 0.586616
	Validation loss decreased (0.597366 --> 0.586616).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 262 - 2019-08-06T13:13:38.057730
	Training Loss: 0.012647 	Validation Loss: 0.574684
	Validation loss decreased (0.586616 --> 0.574684).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 263 - 2019-08-06T13:15:04.568822
	Training Loss: 0.012842 	Validation Loss: 0.605182

Epoch 264 - 2019-08-06T13:16:30.216304
	Training Loss: 0.012705 	Validation Loss: 0.616582

Epoch 265 - 2019-08-06T13:17:55.854767
	Training Loss: 0.013432 	Validation Loss: 0.621749

Epoch 266 - 2019-08-06T13:19:21.477174
	Training Loss: 0.012141 	Validation Loss: 0.513508
	Validation loss decreased (0.574684 --> 0.513508).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 267 - 2019-08-06T13:20:48.005917
	Training Loss: 0.011869 	Validation Loss: 0.569662

Epoch 268 - 2019-08-06T13:22:13.641839
	Training Loss: 0.012749 	Validation Loss: 0.507704
	Validation loss decreased (0.513508 --> 0.507704).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 269 - 2019-08-06T13:23:40.167367
	Training Loss: 0.011297 	Validation Loss: 0.480531
	Validation loss decreased (0.507704 --> 0.480531).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 270 - 2019-08-06T13:25:06.687125
	Training Loss: 0.012328 	Validation Loss: 0.640071

Epoch 271 - 2019-08-06T13:26:32.316733
	Training Loss: 0.012046 	Validation Loss: 0.541989

Epoch 272 - 2019-08-06T13:27:57.976637
	Training Loss: 0.011492 	Validation Loss: 0.545485

Epoch 273 - 2019-08-06T13:29:23.592361
	Training Loss: 0.011649 	Validation Loss: 0.458876
	Validation loss decreased (0.480531 --> 0.458876).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 274 - 2019-08-06T13:30:50.173336
	Training Loss: 0.011498 	Validation Loss: 0.666719

Epoch 275 - 2019-08-06T13:32:15.819001
	Training Loss: 0.012577 	Validation Loss: 0.573069

Epoch 276 - 2019-08-06T13:33:41.452622
	Training Loss: 0.013055 	Validation Loss: 0.535736

Epoch 277 - 2019-08-06T13:35:07.092855
	Training Loss: 0.012965 	Validation Loss: 0.429990
	Validation loss decreased (0.458876 --> 0.429990).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 278 - 2019-08-06T13:36:33.624978
	Training Loss: 0.011860 	Validation Loss: 0.445517

Epoch 279 - 2019-08-06T13:37:59.251927
	Training Loss: 0.011343 	Validation Loss: 0.471413

Epoch 280 - 2019-08-06T13:39:24.895274
	Training Loss: 0.010850 	Validation Loss: 0.413119
	Validation loss decreased (0.429990 --> 0.413119).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 281 - 2019-08-06T13:40:51.414059
	Training Loss: 0.010389 	Validation Loss: 0.444217

Epoch 282 - 2019-08-06T13:42:17.022950
	Training Loss: 0.011324 	Validation Loss: 0.401507
	Validation loss decreased (0.413119 --> 0.401507).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 283 - 2019-08-06T13:43:43.558746
	Training Loss: 0.010586 	Validation Loss: 0.379067
	Validation loss decreased (0.401507 --> 0.379067).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 284 - 2019-08-06T13:45:10.097301
	Training Loss: 0.011442 	Validation Loss: 0.452625

Epoch 285 - 2019-08-06T13:46:35.733219
	Training Loss: 0.011149 	Validation Loss: 0.468000

Epoch 286 - 2019-08-06T13:48:01.347241
	Training Loss: 0.009869 	Validation Loss: 0.386370

Epoch 287 - 2019-08-06T13:49:27.000671
	Training Loss: 0.010721 	Validation Loss: 0.438473

Epoch 288 - 2019-08-06T13:50:52.647242
	Training Loss: 0.010608 	Validation Loss: 0.440260

Epoch 289 - 2019-08-06T13:52:18.301954
	Training Loss: 0.010690 	Validation Loss: 0.414678

Epoch 290 - 2019-08-06T13:53:43.957236
	Training Loss: 0.010341 	Validation Loss: 0.440472

Epoch 291 - 2019-08-06T13:55:09.624498
	Training Loss: 0.010328 	Validation Loss: 0.367358
	Validation loss decreased (0.379067 --> 0.367358).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 292 - 2019-08-06T13:56:36.161392
	Training Loss: 0.011054 	Validation Loss: 0.380506

Epoch 293 - 2019-08-06T13:58:01.788796
	Training Loss: 0.010137 	Validation Loss: 0.341598
	Validation loss decreased (0.367358 --> 0.341598).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 294 - 2019-08-06T13:59:28.303970
	Training Loss: 0.010324 	Validation Loss: 0.435979

Epoch 295 - 2019-08-06T14:00:53.946869
	Training Loss: 0.011147 	Validation Loss: 0.420625

Epoch 296 - 2019-08-06T14:02:19.609361
	Training Loss: 0.011423 	Validation Loss: 0.380068

Epoch 297 - 2019-08-06T14:03:45.268790
	Training Loss: 0.010039 	Validation Loss: 0.378995

Epoch 298 - 2019-08-06T14:05:10.897112
	Training Loss: 0.009658 	Validation Loss: 0.299973
	Validation loss decreased (0.341598 --> 0.299973).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 299 - 2019-08-06T14:06:37.413934
	Training Loss: 0.008883 	Validation Loss: 0.371825

Epoch 300 - 2019-08-06T14:08:03.054520
	Training Loss: 0.010390 	Validation Loss: 0.396236

Epoch 301 - 2019-08-06T14:09:28.684878
	Training Loss: 0.010655 	Validation Loss: 0.386652

Epoch 302 - 2019-08-06T14:10:54.332343
	Training Loss: 0.010648 	Validation Loss: 0.346583

Epoch 303 - 2019-08-06T14:12:19.996452
	Training Loss: 0.011983 	Validation Loss: 0.294242
	Validation loss decreased (0.299973 --> 0.294242).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 304 - 2019-08-06T14:13:46.530747
	Training Loss: 0.010229 	Validation Loss: 0.262410
	Validation loss decreased (0.294242 --> 0.262410).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 305 - 2019-08-06T14:15:13.042826
	Training Loss: 0.009262 	Validation Loss: 0.287155

Epoch 306 - 2019-08-06T14:16:38.705522
	Training Loss: 0.009399 	Validation Loss: 0.267420

Epoch 307 - 2019-08-06T14:18:04.340808
	Training Loss: 0.009204 	Validation Loss: 0.271356

Epoch 308 - 2019-08-06T14:19:29.952607
	Training Loss: 0.009423 	Validation Loss: 0.262044
	Validation loss decreased (0.262410 --> 0.262044).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 309 - 2019-08-06T14:20:56.529488
	Training Loss: 0.010215 	Validation Loss: 0.303028

Epoch 310 - 2019-08-06T14:22:22.189712
	Training Loss: 0.010795 	Validation Loss: 0.219635
	Validation loss decreased (0.262044 --> 0.219635).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 311 - 2019-08-06T14:23:48.707997
	Training Loss: 0.009027 	Validation Loss: 0.256940

Epoch 312 - 2019-08-06T14:25:14.376987
	Training Loss: 0.008810 	Validation Loss: 0.297639

Epoch 313 - 2019-08-06T14:26:40.012465
	Training Loss: 0.009104 	Validation Loss: 0.233927

Epoch 314 - 2019-08-06T14:28:05.633644
	Training Loss: 0.009645 	Validation Loss: 0.367466

Epoch 315 - 2019-08-06T14:29:31.301270
	Training Loss: 0.009682 	Validation Loss: 0.277551

Epoch 316 - 2019-08-06T14:30:56.954733
	Training Loss: 0.008616 	Validation Loss: 0.199900
	Validation loss decreased (0.219635 --> 0.199900).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 317 - 2019-08-06T14:32:23.527079
	Training Loss: 0.010171 	Validation Loss: 0.242938

Epoch 318 - 2019-08-06T14:33:49.177666
	Training Loss: 0.008912 	Validation Loss: 0.246927

Epoch 319 - 2019-08-06T14:35:14.824618
	Training Loss: 0.009234 	Validation Loss: 0.215003

Epoch 320 - 2019-08-06T14:36:40.440516
	Training Loss: 0.008959 	Validation Loss: 0.195953
	Validation loss decreased (0.199900 --> 0.195953).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 321 - 2019-08-06T14:38:07.093828
	Training Loss: 0.008843 	Validation Loss: 0.236529

Epoch 322 - 2019-08-06T14:39:32.748226
	Training Loss: 0.008148 	Validation Loss: 0.169360
	Validation loss decreased (0.195953 --> 0.169360).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 323 - 2019-08-06T14:40:59.264720
	Training Loss: 0.008104 	Validation Loss: 0.209970

Epoch 324 - 2019-08-06T14:42:24.887261
	Training Loss: 0.008956 	Validation Loss: 0.152940
	Validation loss decreased (0.169360 --> 0.152940).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 325 - 2019-08-06T14:43:51.413612
	Training Loss: 0.007967 	Validation Loss: 0.235670

Epoch 326 - 2019-08-06T14:45:17.081012
	Training Loss: 0.007680 	Validation Loss: 0.155665

Epoch 327 - 2019-08-06T14:46:42.715580
	Training Loss: 0.006857 	Validation Loss: 0.187326

Epoch 328 - 2019-08-06T14:48:08.343117
	Training Loss: 0.007793 	Validation Loss: 0.170714

Epoch 329 - 2019-08-06T14:49:34.003957
	Training Loss: 0.009271 	Validation Loss: 0.153496

Epoch 330 - 2019-08-06T14:50:59.647000
	Training Loss: 0.007901 	Validation Loss: 0.183986

Epoch 331 - 2019-08-06T14:52:25.282981
	Training Loss: 0.008214 	Validation Loss: 0.132288
	Validation loss decreased (0.152940 --> 0.132288).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 332 - 2019-08-06T14:53:51.811479
	Training Loss: 0.007462 	Validation Loss: 0.143218

Epoch 333 - 2019-08-06T14:55:17.443386
	Training Loss: 0.007459 	Validation Loss: 0.202203

Epoch 334 - 2019-08-06T14:56:43.076505
	Training Loss: 0.008780 	Validation Loss: 0.163276

Epoch 335 - 2019-08-06T14:58:08.677853
	Training Loss: 0.008145 	Validation Loss: 0.110577
	Validation loss decreased (0.132288 --> 0.110577).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 336 - 2019-08-06T14:59:35.212456
	Training Loss: 0.007405 	Validation Loss: 0.130955

Epoch 337 - 2019-08-06T15:01:00.833642
	Training Loss: 0.007715 	Validation Loss: 0.142506

Epoch 338 - 2019-08-06T15:02:26.443222
	Training Loss: 0.007255 	Validation Loss: 0.158664

Epoch 339 - 2019-08-06T15:03:52.063941
	Training Loss: 0.008286 	Validation Loss: 0.137483

Epoch 340 - 2019-08-06T15:05:17.707245
	Training Loss: 0.007601 	Validation Loss: 0.115513

Epoch 341 - 2019-08-06T15:06:43.328539
	Training Loss: 0.007305 	Validation Loss: 0.117564

Epoch 342 - 2019-08-06T15:08:08.956857
	Training Loss: 0.006870 	Validation Loss: 0.131520

Epoch 343 - 2019-08-06T15:09:34.602985
	Training Loss: 0.007661 	Validation Loss: 0.109457
	Validation loss decreased (0.110577 --> 0.109457).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 344 - 2019-08-06T15:11:01.171923
	Training Loss: 0.007092 	Validation Loss: 0.130343

Epoch 345 - 2019-08-06T15:12:26.797892
	Training Loss: 0.007008 	Validation Loss: 0.111953

Epoch 346 - 2019-08-06T15:13:52.442308
	Training Loss: 0.006612 	Validation Loss: 0.082932
	Validation loss decreased (0.109457 --> 0.082932).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 347 - 2019-08-06T15:15:18.992229
	Training Loss: 0.006634 	Validation Loss: 0.138981

Epoch 348 - 2019-08-06T15:16:44.670211
	Training Loss: 0.007138 	Validation Loss: 0.088938

Epoch 349 - 2019-08-06T15:18:10.285740
	Training Loss: 0.006834 	Validation Loss: 0.083081

Epoch 350 - 2019-08-06T15:19:35.937004
	Training Loss: 0.007266 	Validation Loss: 0.117576

Epoch 351 - 2019-08-06T15:21:01.604540
	Training Loss: 0.007154 	Validation Loss: 0.109409

Epoch 352 - 2019-08-06T15:22:27.255682
	Training Loss: 0.007368 	Validation Loss: 0.088779

Epoch 353 - 2019-08-06T15:23:52.862564
	Training Loss: 0.007341 	Validation Loss: 0.072013
	Validation loss decreased (0.082932 --> 0.072013).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 354 - 2019-08-06T15:25:19.399068
	Training Loss: 0.007644 	Validation Loss: 0.069985
	Validation loss decreased (0.072013 --> 0.069985).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 355 - 2019-08-06T15:26:45.922093
	Training Loss: 0.006415 	Validation Loss: 0.103303

Epoch 356 - 2019-08-06T15:28:11.589014
	Training Loss: 0.006709 	Validation Loss: 0.059349
	Validation loss decreased (0.069985 --> 0.059349).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 357 - 2019-08-06T15:29:38.138063
	Training Loss: 0.007012 	Validation Loss: 0.107596

Epoch 358 - 2019-08-06T15:31:03.791926
	Training Loss: 0.008084 	Validation Loss: 0.114785

Epoch 359 - 2019-08-06T15:32:29.449476
	Training Loss: 0.006143 	Validation Loss: 0.058632
	Validation loss decreased (0.059349 --> 0.058632).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 360 - 2019-08-06T15:33:55.993721
	Training Loss: 0.006030 	Validation Loss: 0.066889

Epoch 361 - 2019-08-06T15:35:21.657134
	Training Loss: 0.005966 	Validation Loss: 0.054808
	Validation loss decreased (0.058632 --> 0.054808).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 362 - 2019-08-06T15:36:48.224858
	Training Loss: 0.006234 	Validation Loss: 0.061621

Epoch 363 - 2019-08-06T15:38:13.870076
	Training Loss: 0.006668 	Validation Loss: 0.084514

Epoch 364 - 2019-08-06T15:39:39.549468
	Training Loss: 0.006846 	Validation Loss: 0.052238
	Validation loss decreased (0.054808 --> 0.052238).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 365 - 2019-08-06T15:41:06.175377
	Training Loss: 0.006360 	Validation Loss: 0.086543

Epoch 366 - 2019-08-06T15:42:31.858795
	Training Loss: 0.007348 	Validation Loss: 0.082204

Epoch 367 - 2019-08-06T15:43:57.506822
	Training Loss: 0.006390 	Validation Loss: 0.063439

Epoch 368 - 2019-08-06T15:45:23.138286
	Training Loss: 0.005752 	Validation Loss: 0.049603
	Validation loss decreased (0.052238 --> 0.049603).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 369 - 2019-08-06T15:46:49.758816
	Training Loss: 0.005545 	Validation Loss: 0.045656
	Validation loss decreased (0.049603 --> 0.045656).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 370 - 2019-08-06T15:48:16.320111
	Training Loss: 0.005159 	Validation Loss: 0.047171

Epoch 371 - 2019-08-06T15:49:41.975358
	Training Loss: 0.005641 	Validation Loss: 0.045575
	Validation loss decreased (0.045656 --> 0.045575).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 372 - 2019-08-06T15:51:08.611946
	Training Loss: 0.005653 	Validation Loss: 0.038474
	Validation loss decreased (0.045575 --> 0.038474).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 373 - 2019-08-06T15:52:35.195608
	Training Loss: 0.005696 	Validation Loss: 0.049793

Epoch 374 - 2019-08-06T15:54:00.831982
	Training Loss: 0.006256 	Validation Loss: 0.041066

Epoch 375 - 2019-08-06T15:55:26.469692
	Training Loss: 0.005890 	Validation Loss: 0.049069

Epoch 376 - 2019-08-06T15:56:52.098118
	Training Loss: 0.005477 	Validation Loss: 0.047050

Epoch 377 - 2019-08-06T15:58:17.738841
	Training Loss: 0.005968 	Validation Loss: 0.058528

Epoch 378 - 2019-08-06T15:59:43.373497
	Training Loss: 0.006609 	Validation Loss: 0.040310

Epoch 379 - 2019-08-06T16:01:09.016389
	Training Loss: 0.004762 	Validation Loss: 0.029286
	Validation loss decreased (0.038474 --> 0.029286).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 380 - 2019-08-06T16:02:35.559298
	Training Loss: 0.006155 	Validation Loss: 0.035578

Epoch 381 - 2019-08-06T16:04:01.179179
	Training Loss: 0.006690 	Validation Loss: 0.077899

Epoch 382 - 2019-08-06T16:05:26.797762
	Training Loss: 0.006163 	Validation Loss: 0.038952

Epoch 383 - 2019-08-06T16:06:52.446965
	Training Loss: 0.005455 	Validation Loss: 0.036894

Epoch 384 - 2019-08-06T16:08:18.127733
	Training Loss: 0.005969 	Validation Loss: 0.030162

Epoch 385 - 2019-08-06T16:09:43.757114
	Training Loss: 0.005715 	Validation Loss: 0.047531

Epoch 386 - 2019-08-06T16:11:09.374604
	Training Loss: 0.005367 	Validation Loss: 0.031169

Epoch 387 - 2019-08-06T16:12:35.024160
	Training Loss: 0.005409 	Validation Loss: 0.025417
	Validation loss decreased (0.029286 --> 0.025417).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 388 - 2019-08-06T16:14:01.605310
	Training Loss: 0.005320 	Validation Loss: 0.017467
	Validation loss decreased (0.025417 --> 0.017467).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 389 - 2019-08-06T16:15:28.145833
	Training Loss: 0.004837 	Validation Loss: 0.025228

Epoch 390 - 2019-08-06T16:16:53.798921
	Training Loss: 0.004547 	Validation Loss: 0.020291

Epoch 391 - 2019-08-06T16:18:19.431403
	Training Loss: 0.004348 	Validation Loss: 0.021897

Epoch 392 - 2019-08-06T16:19:45.036273
	Training Loss: 0.004550 	Validation Loss: 0.015440
	Validation loss decreased (0.017467 --> 0.015440).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 393 - 2019-08-06T16:21:11.586494
	Training Loss: 0.004844 	Validation Loss: 0.013454
	Validation loss decreased (0.015440 --> 0.013454).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 394 - 2019-08-06T16:22:38.173730
	Training Loss: 0.004371 	Validation Loss: 0.020151

Epoch 395 - 2019-08-06T16:24:03.813804
	Training Loss: 0.005501 	Validation Loss: 0.019017

Epoch 396 - 2019-08-06T16:25:29.437405
	Training Loss: 0.004941 	Validation Loss: 0.015084

Epoch 397 - 2019-08-06T16:26:55.062953
	Training Loss: 0.004536 	Validation Loss: 0.018251

Epoch 398 - 2019-08-06T16:28:20.672384
	Training Loss: 0.005117 	Validation Loss: 0.011902
	Validation loss decreased (0.013454 --> 0.011902).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 399 - 2019-08-06T16:29:47.211237
	Training Loss: 0.004120 	Validation Loss: 0.015917

Epoch 400 - 2019-08-06T16:31:12.870301
	Training Loss: 0.004148 	Validation Loss: 0.015349

Epoch 401 - 2019-08-06T16:32:38.477293
	Training Loss: 0.004306 	Validation Loss: 0.013055

Epoch 402 - 2019-08-06T16:34:04.120795
	Training Loss: 0.004865 	Validation Loss: 0.018808

Epoch 403 - 2019-08-06T16:35:29.810739
	Training Loss: 0.004475 	Validation Loss: 0.013467

Epoch 404 - 2019-08-06T16:36:55.472437
	Training Loss: 0.004605 	Validation Loss: 0.011265
	Validation loss decreased (0.011902 --> 0.011265).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 405 - 2019-08-06T16:38:22.017985
	Training Loss: 0.004525 	Validation Loss: 0.015039

Epoch 406 - 2019-08-06T16:39:47.688202
	Training Loss: 0.004494 	Validation Loss: 0.011652

Epoch 407 - 2019-08-06T16:41:13.350955
	Training Loss: 0.004344 	Validation Loss: 0.007311
	Validation loss decreased (0.011265 --> 0.007311).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 408 - 2019-08-06T16:42:39.894454
	Training Loss: 0.004101 	Validation Loss: 0.010337

Epoch 409 - 2019-08-06T16:44:05.588834
	Training Loss: 0.004159 	Validation Loss: 0.009712

Epoch 410 - 2019-08-06T16:45:31.265366
	Training Loss: 0.004159 	Validation Loss: 0.013435

Epoch 411 - 2019-08-06T16:46:56.921976
	Training Loss: 0.004463 	Validation Loss: 0.016991

Epoch 412 - 2019-08-06T16:48:22.574263
	Training Loss: 0.004453 	Validation Loss: 0.004843
	Validation loss decreased (0.007311 --> 0.004843).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 413 - 2019-08-06T16:49:49.107097
	Training Loss: 0.003844 	Validation Loss: 0.005412

Epoch 414 - 2019-08-06T16:51:14.767883
	Training Loss: 0.003624 	Validation Loss: 0.005592

Epoch 415 - 2019-08-06T16:52:40.910394
	Training Loss: 0.003778 	Validation Loss: 0.007107

Epoch 416 - 2019-08-06T16:54:06.971413
	Training Loss: 0.004264 	Validation Loss: 0.005797

Epoch 417 - 2019-08-06T16:55:32.659604
	Training Loss: 0.004084 	Validation Loss: 0.005047

Epoch 418 - 2019-08-06T16:56:58.348190
	Training Loss: 0.004190 	Validation Loss: 0.009523

Epoch 419 - 2019-08-06T16:58:24.323090
	Training Loss: 0.004123 	Validation Loss: 0.005684

Epoch 420 - 2019-08-06T16:59:50.389558
	Training Loss: 0.004335 	Validation Loss: 0.003400
	Validation loss decreased (0.004843 --> 0.003400).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 421 - 2019-08-06T17:01:16.994670
	Training Loss: 0.004463 	Validation Loss: 0.011301

Epoch 422 - 2019-08-06T17:02:42.692591
	Training Loss: 0.003608 	Validation Loss: 0.003979

Epoch 423 - 2019-08-06T17:04:08.655802
	Training Loss: 0.004492 	Validation Loss: 0.010296

Epoch 424 - 2019-08-06T17:05:34.414835
	Training Loss: 0.004198 	Validation Loss: 0.004358

Epoch 425 - 2019-08-06T17:07:00.113537
	Training Loss: 0.003445 	Validation Loss: 0.005527

Epoch 426 - 2019-08-06T17:08:25.810847
	Training Loss: 0.003627 	Validation Loss: 0.002702
	Validation loss decreased (0.003400 --> 0.002702).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 427 - 2019-08-06T17:09:52.713080
	Training Loss: 0.003870 	Validation Loss: 0.003584

Epoch 428 - 2019-08-06T17:11:18.364839
	Training Loss: 0.003418 	Validation Loss: 0.005197

Epoch 429 - 2019-08-06T17:12:44.048926
	Training Loss: 0.003952 	Validation Loss: 0.006172

Epoch 430 - 2019-08-06T17:14:09.722631
	Training Loss: 0.003346 	Validation Loss: 0.002680
	Validation loss decreased (0.002702 --> 0.002680).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 431 - 2019-08-06T17:15:36.697060
	Training Loss: 0.003539 	Validation Loss: 0.003762

Epoch 432 - 2019-08-06T17:17:02.399955
	Training Loss: 0.003215 	Validation Loss: 0.002393
	Validation loss decreased (0.002680 --> 0.002393).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 433 - 2019-08-06T17:18:28.944312
	Training Loss: 0.003116 	Validation Loss: 0.001866
	Validation loss decreased (0.002393 --> 0.001866).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 434 - 2019-08-06T17:19:55.548327
	Training Loss: 0.003457 	Validation Loss: 0.003134

Epoch 435 - 2019-08-06T17:21:21.513087
	Training Loss: 0.003177 	Validation Loss: 0.002849

Epoch 436 - 2019-08-06T17:22:48.313291
	Training Loss: 0.004556 	Validation Loss: 0.003058

Epoch 437 - 2019-08-06T17:24:14.195782
	Training Loss: 0.003532 	Validation Loss: 0.001889

Epoch 438 - 2019-08-06T17:25:39.904748
	Training Loss: 0.003303 	Validation Loss: 0.004182

Epoch 439 - 2019-08-06T17:27:05.602206
	Training Loss: 0.003663 	Validation Loss: 0.001504
	Validation loss decreased (0.001866 --> 0.001504).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 440 - 2019-08-06T17:28:32.223716
	Training Loss: 0.003039 	Validation Loss: 0.001244
	Validation loss decreased (0.001504 --> 0.001244).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 441 - 2019-08-06T17:29:59.131346
	Training Loss: 0.002557 	Validation Loss: 0.000947
	Validation loss decreased (0.001244 --> 0.000947).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 442 - 2019-08-06T17:31:25.688210
	Training Loss: 0.002827 	Validation Loss: 0.002001

Epoch 443 - 2019-08-06T17:32:51.367429
	Training Loss: 0.003132 	Validation Loss: 0.001786

Epoch 444 - 2019-08-06T17:34:17.245478
	Training Loss: 0.002910 	Validation Loss: 0.001953

Epoch 445 - 2019-08-06T17:35:42.956218
	Training Loss: 0.002843 	Validation Loss: 0.001117

Epoch 446 - 2019-08-06T17:37:08.655029
	Training Loss: 0.002754 	Validation Loss: 0.001069

Epoch 447 - 2019-08-06T17:38:34.366490
	Training Loss: 0.002729 	Validation Loss: 0.001708

Epoch 448 - 2019-08-06T17:40:00.113523
	Training Loss: 0.002776 	Validation Loss: 0.001229

Epoch 449 - 2019-08-06T17:41:25.842263
	Training Loss: 0.002881 	Validation Loss: 0.003064

Epoch 450 - 2019-08-06T17:42:51.566739
	Training Loss: 0.002398 	Validation Loss: 0.000761
	Validation loss decreased (0.000947 --> 0.000761).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 451 - 2019-08-06T17:44:18.260050
	Training Loss: 0.003038 	Validation Loss: 0.000850

Epoch 452 - 2019-08-06T17:45:43.994631
	Training Loss: 0.002568 	Validation Loss: 0.000600
	Validation loss decreased (0.000761 --> 0.000600).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 453 - 2019-08-06T17:47:10.589369
	Training Loss: 0.003025 	Validation Loss: 0.001025

Epoch 454 - 2019-08-06T17:48:36.277043
	Training Loss: 0.002106 	Validation Loss: 0.000572
	Validation loss decreased (0.000600 --> 0.000572).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 455 - 2019-08-06T17:50:03.194093
	Training Loss: 0.002362 	Validation Loss: 0.001061

Epoch 456 - 2019-08-06T17:51:28.849999
	Training Loss: 0.002979 	Validation Loss: 0.000764

Epoch 457 - 2019-08-06T17:52:54.508920
	Training Loss: 0.003545 	Validation Loss: 0.002006

Epoch 458 - 2019-08-06T17:54:20.153259
	Training Loss: 0.003047 	Validation Loss: 0.001930

Epoch 459 - 2019-08-06T17:55:45.817396
	Training Loss: 0.003429 	Validation Loss: 0.000514
	Validation loss decreased (0.000572 --> 0.000514).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 460 - 2019-08-06T17:57:12.385748
	Training Loss: 0.002723 	Validation Loss: 0.000947

Epoch 461 - 2019-08-06T17:58:38.046569
	Training Loss: 0.002796 	Validation Loss: 0.000769

Epoch 462 - 2019-08-06T18:00:03.689382
	Training Loss: 0.001862 	Validation Loss: 0.000483
	Validation loss decreased (0.000514 --> 0.000483).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 463 - 2019-08-06T18:01:30.278951
	Training Loss: 0.003536 	Validation Loss: 0.000637

Epoch 464 - 2019-08-06T18:02:55.956260
	Training Loss: 0.002366 	Validation Loss: 0.000316
	Validation loss decreased (0.000483 --> 0.000316).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 465 - 2019-08-06T18:04:22.542739
	Training Loss: 0.002138 	Validation Loss: 0.000365

Epoch 466 - 2019-08-06T18:05:48.332571
	Training Loss: 0.002387 	Validation Loss: 0.001031

Epoch 467 - 2019-08-06T18:07:14.019257
	Training Loss: 0.002488 	Validation Loss: 0.000661

Epoch 468 - 2019-08-06T18:08:39.723008
	Training Loss: 0.002424 	Validation Loss: 0.000419

Epoch 469 - 2019-08-06T18:10:05.415290
	Training Loss: 0.002253 	Validation Loss: 0.000291
	Validation loss decreased (0.000316 --> 0.000291).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 470 - 2019-08-06T18:11:32.286915
	Training Loss: 0.002189 	Validation Loss: 0.000207
	Validation loss decreased (0.000291 --> 0.000207).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 471 - 2019-08-06T18:12:59.004560
	Training Loss: 0.001826 	Validation Loss: 0.000307

Epoch 472 - 2019-08-06T18:14:24.701832
	Training Loss: 0.001974 	Validation Loss: 0.000355

Epoch 473 - 2019-08-06T18:15:50.379043
	Training Loss: 0.001966 	Validation Loss: 0.000252

Epoch 474 - 2019-08-06T18:17:16.050041
	Training Loss: 0.001981 	Validation Loss: 0.000374

Epoch 475 - 2019-08-06T18:18:41.713810
	Training Loss: 0.001793 	Validation Loss: 0.000245

Epoch 476 - 2019-08-06T18:20:07.386128
	Training Loss: 0.002115 	Validation Loss: 0.000324

Epoch 477 - 2019-08-06T18:21:33.083964
	Training Loss: 0.001951 	Validation Loss: 0.000341

Epoch 478 - 2019-08-06T18:22:58.767265
	Training Loss: 0.001932 	Validation Loss: 0.000320

Epoch 479 - 2019-08-06T18:24:24.427287
	Training Loss: 0.002527 	Validation Loss: 0.000503

Epoch 480 - 2019-08-06T18:25:50.075419
	Training Loss: 0.002424 	Validation Loss: 0.000640

Epoch 481 - 2019-08-06T18:27:15.714955
	Training Loss: 0.001932 	Validation Loss: 0.000289

Epoch 482 - 2019-08-06T18:28:41.378454
	Training Loss: 0.002023 	Validation Loss: 0.000207

Epoch 483 - 2019-08-06T18:30:07.026427
	Training Loss: 0.002261 	Validation Loss: 0.000277

Epoch 484 - 2019-08-06T18:31:32.777200
	Training Loss: 0.002293 	Validation Loss: 0.000423

Epoch 485 - 2019-08-06T18:32:58.651413
	Training Loss: 0.002087 	Validation Loss: 0.000210

Epoch 486 - 2019-08-06T18:34:24.351010
	Training Loss: 0.001546 	Validation Loss: 0.000164
	Validation loss decreased (0.000207 --> 0.000164).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 487 - 2019-08-06T18:35:50.953128
	Training Loss: 0.001634 	Validation Loss: 0.000152
	Validation loss decreased (0.000164 --> 0.000152).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 488 - 2019-08-06T18:37:17.810757
	Training Loss: 0.001892 	Validation Loss: 0.000233

Epoch 489 - 2019-08-06T18:38:43.474634
	Training Loss: 0.001670 	Validation Loss: 0.000135
	Validation loss decreased (0.000152 --> 0.000135).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 490 - 2019-08-06T18:40:10.010183
	Training Loss: 0.001766 	Validation Loss: 0.000202

Epoch 491 - 2019-08-06T18:41:35.674476
	Training Loss: 0.002003 	Validation Loss: 0.000491

Epoch 492 - 2019-08-06T18:43:01.451712
	Training Loss: 0.002432 	Validation Loss: 0.000218

Epoch 493 - 2019-08-06T18:44:27.515619
	Training Loss: 0.002013 	Validation Loss: 0.000163

Epoch 494 - 2019-08-06T18:45:53.248935
	Training Loss: 0.002240 	Validation Loss: 0.000223

Epoch 495 - 2019-08-06T18:47:18.941930
	Training Loss: 0.001868 	Validation Loss: 0.000121
	Validation loss decreased (0.000135 --> 0.000121).  Saving model ...
	Saving the model in path: data/models/2019-08-06T07:00:22.659687.pth

Epoch 496 - 2019-08-06T18:48:45.550955
	Training Loss: 0.002570 	Validation Loss: 0.000900

Epoch 497 - 2019-08-06T18:50:11.291207
	Training Loss: 0.001911 	Validation Loss: 0.000186

Epoch 498 - 2019-08-06T18:51:37.228694
	Training Loss: 0.001564 	Validation Loss: 0.000178

Epoch 499 - 2019-08-06T18:53:02.976525
	Training Loss: 0.002333 	Validation Loss: 0.000237

Epoch 500 - 2019-08-06T18:54:28.686114
	Training Loss: 0.002223 	Validation Loss: 0.000223

Training elapsed time: 11:56:11.14
